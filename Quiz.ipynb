{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First Task of the Quiz\n",
        "Time Series Forcasting Task."
      ],
      "metadata": {
        "id": "WbzxgkgcNZmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSkafzNwHn4j",
        "outputId": "f8336544-646d-49e7-9ac2-d26fa7ddd5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 - 5s - loss: 0.0326 - 5s/epoch - 80ms/step\n",
            "Epoch 2/100\n",
            "63/63 - 1s - loss: 9.8236e-04 - 732ms/epoch - 12ms/step\n",
            "Epoch 3/100\n",
            "63/63 - 1s - loss: 9.4843e-04 - 742ms/epoch - 12ms/step\n",
            "Epoch 4/100\n",
            "63/63 - 1s - loss: 9.2389e-04 - 746ms/epoch - 12ms/step\n",
            "Epoch 5/100\n",
            "63/63 - 1s - loss: 8.9725e-04 - 719ms/epoch - 11ms/step\n",
            "Epoch 6/100\n",
            "63/63 - 1s - loss: 9.0026e-04 - 739ms/epoch - 12ms/step\n",
            "Epoch 7/100\n",
            "63/63 - 1s - loss: 8.8432e-04 - 766ms/epoch - 12ms/step\n",
            "Epoch 8/100\n",
            "63/63 - 1s - loss: 8.8595e-04 - 1s/epoch - 18ms/step\n",
            "Epoch 9/100\n",
            "63/63 - 1s - loss: 8.8609e-04 - 1s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "63/63 - 1s - loss: 8.9969e-04 - 890ms/epoch - 14ms/step\n",
            "Epoch 11/100\n",
            "63/63 - 1s - loss: 8.8785e-04 - 733ms/epoch - 12ms/step\n",
            "Epoch 12/100\n",
            "63/63 - 1s - loss: 8.5040e-04 - 721ms/epoch - 11ms/step\n",
            "Epoch 13/100\n",
            "63/63 - 1s - loss: 8.0835e-04 - 749ms/epoch - 12ms/step\n",
            "Epoch 14/100\n",
            "63/63 - 1s - loss: 8.1994e-04 - 730ms/epoch - 12ms/step\n",
            "Epoch 15/100\n",
            "63/63 - 1s - loss: 8.2612e-04 - 729ms/epoch - 12ms/step\n",
            "Epoch 16/100\n",
            "63/63 - 1s - loss: 7.8253e-04 - 709ms/epoch - 11ms/step\n",
            "Epoch 17/100\n",
            "63/63 - 1s - loss: 7.8747e-04 - 743ms/epoch - 12ms/step\n",
            "Epoch 18/100\n",
            "63/63 - 1s - loss: 8.0714e-04 - 726ms/epoch - 12ms/step\n",
            "Epoch 19/100\n",
            "63/63 - 1s - loss: 7.0582e-04 - 712ms/epoch - 11ms/step\n",
            "Epoch 20/100\n",
            "63/63 - 1s - loss: 7.1052e-04 - 748ms/epoch - 12ms/step\n",
            "Epoch 21/100\n",
            "63/63 - 1s - loss: 6.5293e-04 - 740ms/epoch - 12ms/step\n",
            "Epoch 22/100\n",
            "63/63 - 1s - loss: 6.5721e-04 - 741ms/epoch - 12ms/step\n",
            "Epoch 23/100\n",
            "63/63 - 1s - loss: 6.9396e-04 - 771ms/epoch - 12ms/step\n",
            "Epoch 24/100\n",
            "63/63 - 1s - loss: 6.0293e-04 - 1s/epoch - 18ms/step\n",
            "Epoch 25/100\n",
            "63/63 - 1s - loss: 6.4812e-04 - 1s/epoch - 19ms/step\n",
            "Epoch 26/100\n",
            "63/63 - 1s - loss: 5.9326e-04 - 880ms/epoch - 14ms/step\n",
            "Epoch 27/100\n",
            "63/63 - 1s - loss: 5.9787e-04 - 745ms/epoch - 12ms/step\n",
            "Epoch 28/100\n",
            "63/63 - 1s - loss: 5.5922e-04 - 745ms/epoch - 12ms/step\n",
            "Epoch 29/100\n",
            "63/63 - 1s - loss: 5.3789e-04 - 729ms/epoch - 12ms/step\n",
            "Epoch 30/100\n",
            "63/63 - 1s - loss: 5.0912e-04 - 738ms/epoch - 12ms/step\n",
            "Epoch 31/100\n",
            "63/63 - 1s - loss: 4.9734e-04 - 735ms/epoch - 12ms/step\n",
            "Epoch 32/100\n",
            "63/63 - 1s - loss: 5.1405e-04 - 736ms/epoch - 12ms/step\n",
            "Epoch 33/100\n",
            "63/63 - 1s - loss: 5.0064e-04 - 725ms/epoch - 12ms/step\n",
            "Epoch 34/100\n",
            "63/63 - 1s - loss: 4.6795e-04 - 731ms/epoch - 12ms/step\n",
            "Epoch 35/100\n",
            "63/63 - 1s - loss: 5.0419e-04 - 737ms/epoch - 12ms/step\n",
            "Epoch 36/100\n",
            "63/63 - 1s - loss: 5.3269e-04 - 758ms/epoch - 12ms/step\n",
            "Epoch 37/100\n",
            "63/63 - 1s - loss: 4.5680e-04 - 719ms/epoch - 11ms/step\n",
            "Epoch 38/100\n",
            "63/63 - 1s - loss: 4.8052e-04 - 722ms/epoch - 11ms/step\n",
            "Epoch 39/100\n",
            "63/63 - 1s - loss: 4.0679e-04 - 818ms/epoch - 13ms/step\n",
            "Epoch 40/100\n",
            "63/63 - 1s - loss: 4.1512e-04 - 1s/epoch - 18ms/step\n",
            "Epoch 41/100\n",
            "63/63 - 1s - loss: 4.6883e-04 - 1s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "63/63 - 1s - loss: 4.3611e-04 - 837ms/epoch - 13ms/step\n",
            "Epoch 43/100\n",
            "63/63 - 1s - loss: 4.1180e-04 - 720ms/epoch - 11ms/step\n",
            "Epoch 44/100\n",
            "63/63 - 1s - loss: 4.1963e-04 - 748ms/epoch - 12ms/step\n",
            "Epoch 45/100\n",
            "63/63 - 1s - loss: 4.5034e-04 - 733ms/epoch - 12ms/step\n",
            "Epoch 46/100\n",
            "63/63 - 1s - loss: 4.3294e-04 - 731ms/epoch - 12ms/step\n",
            "Epoch 47/100\n",
            "63/63 - 1s - loss: 3.9164e-04 - 735ms/epoch - 12ms/step\n",
            "Epoch 48/100\n",
            "63/63 - 1s - loss: 3.8809e-04 - 740ms/epoch - 12ms/step\n",
            "Epoch 49/100\n",
            "63/63 - 1s - loss: 3.4324e-04 - 729ms/epoch - 12ms/step\n",
            "Epoch 50/100\n",
            "63/63 - 1s - loss: 3.4863e-04 - 720ms/epoch - 11ms/step\n",
            "Epoch 51/100\n",
            "63/63 - 1s - loss: 3.5340e-04 - 746ms/epoch - 12ms/step\n",
            "Epoch 52/100\n",
            "63/63 - 1s - loss: 3.3346e-04 - 733ms/epoch - 12ms/step\n",
            "Epoch 53/100\n",
            "63/63 - 1s - loss: 3.6508e-04 - 724ms/epoch - 11ms/step\n",
            "Epoch 54/100\n",
            "63/63 - 1s - loss: 4.2131e-04 - 727ms/epoch - 12ms/step\n",
            "Epoch 55/100\n",
            "63/63 - 1s - loss: 3.7488e-04 - 860ms/epoch - 14ms/step\n",
            "Epoch 56/100\n",
            "63/63 - 1s - loss: 3.1369e-04 - 1s/epoch - 18ms/step\n",
            "Epoch 57/100\n",
            "63/63 - 1s - loss: 3.5413e-04 - 1s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "63/63 - 1s - loss: 3.4134e-04 - 777ms/epoch - 12ms/step\n",
            "Epoch 59/100\n",
            "63/63 - 1s - loss: 3.3710e-04 - 754ms/epoch - 12ms/step\n",
            "Epoch 60/100\n",
            "63/63 - 1s - loss: 3.0799e-04 - 739ms/epoch - 12ms/step\n",
            "Epoch 61/100\n",
            "63/63 - 1s - loss: 3.2346e-04 - 725ms/epoch - 12ms/step\n",
            "Epoch 62/100\n",
            "63/63 - 1s - loss: 3.0763e-04 - 752ms/epoch - 12ms/step\n",
            "Epoch 63/100\n",
            "63/63 - 1s - loss: 3.8056e-04 - 777ms/epoch - 12ms/step\n",
            "Epoch 64/100\n",
            "63/63 - 1s - loss: 3.2271e-04 - 752ms/epoch - 12ms/step\n",
            "Epoch 65/100\n",
            "63/63 - 1s - loss: 3.0236e-04 - 743ms/epoch - 12ms/step\n",
            "Epoch 66/100\n",
            "63/63 - 1s - loss: 3.0118e-04 - 731ms/epoch - 12ms/step\n",
            "Epoch 67/100\n",
            "63/63 - 1s - loss: 2.7937e-04 - 739ms/epoch - 12ms/step\n",
            "Epoch 68/100\n",
            "63/63 - 1s - loss: 2.9548e-04 - 729ms/epoch - 12ms/step\n",
            "Epoch 69/100\n",
            "63/63 - 1s - loss: 2.7927e-04 - 738ms/epoch - 12ms/step\n",
            "Epoch 70/100\n",
            "63/63 - 1s - loss: 2.8732e-04 - 748ms/epoch - 12ms/step\n",
            "Epoch 71/100\n",
            "63/63 - 1s - loss: 3.2941e-04 - 982ms/epoch - 16ms/step\n",
            "Epoch 72/100\n",
            "63/63 - 1s - loss: 2.9819e-04 - 1s/epoch - 18ms/step\n",
            "Epoch 73/100\n",
            "63/63 - 1s - loss: 2.7014e-04 - 1s/epoch - 18ms/step\n",
            "Epoch 74/100\n",
            "63/63 - 1s - loss: 2.8310e-04 - 723ms/epoch - 11ms/step\n",
            "Epoch 75/100\n",
            "63/63 - 1s - loss: 2.8473e-04 - 744ms/epoch - 12ms/step\n",
            "Epoch 76/100\n",
            "63/63 - 1s - loss: 2.6367e-04 - 749ms/epoch - 12ms/step\n",
            "Epoch 77/100\n",
            "63/63 - 1s - loss: 2.9747e-04 - 737ms/epoch - 12ms/step\n",
            "Epoch 78/100\n",
            "63/63 - 1s - loss: 2.6154e-04 - 740ms/epoch - 12ms/step\n",
            "Epoch 79/100\n",
            "63/63 - 1s - loss: 2.5672e-04 - 739ms/epoch - 12ms/step\n",
            "Epoch 80/100\n",
            "63/63 - 1s - loss: 2.9166e-04 - 755ms/epoch - 12ms/step\n",
            "Epoch 81/100\n",
            "63/63 - 1s - loss: 2.6118e-04 - 749ms/epoch - 12ms/step\n",
            "Epoch 82/100\n",
            "63/63 - 1s - loss: 2.5645e-04 - 740ms/epoch - 12ms/step\n",
            "Epoch 83/100\n",
            "63/63 - 1s - loss: 2.6494e-04 - 747ms/epoch - 12ms/step\n",
            "Epoch 84/100\n",
            "63/63 - 1s - loss: 2.6465e-04 - 742ms/epoch - 12ms/step\n",
            "Epoch 85/100\n",
            "63/63 - 1s - loss: 2.6698e-04 - 744ms/epoch - 12ms/step\n",
            "Epoch 86/100\n",
            "63/63 - 1s - loss: 2.7273e-04 - 731ms/epoch - 12ms/step\n",
            "Epoch 87/100\n",
            "63/63 - 1s - loss: 2.7649e-04 - 1s/epoch - 17ms/step\n",
            "Epoch 88/100\n",
            "63/63 - 1s - loss: 2.5760e-04 - 1s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "63/63 - 1s - loss: 2.5125e-04 - 975ms/epoch - 15ms/step\n",
            "Epoch 90/100\n",
            "63/63 - 1s - loss: 2.6939e-04 - 739ms/epoch - 12ms/step\n",
            "Epoch 91/100\n",
            "63/63 - 1s - loss: 2.9910e-04 - 758ms/epoch - 12ms/step\n",
            "Epoch 92/100\n",
            "63/63 - 1s - loss: 2.7796e-04 - 759ms/epoch - 12ms/step\n",
            "Epoch 93/100\n",
            "63/63 - 1s - loss: 2.6409e-04 - 737ms/epoch - 12ms/step\n",
            "Epoch 94/100\n",
            "63/63 - 1s - loss: 2.4592e-04 - 757ms/epoch - 12ms/step\n",
            "Epoch 95/100\n",
            "63/63 - 1s - loss: 2.6061e-04 - 759ms/epoch - 12ms/step\n",
            "Epoch 96/100\n",
            "63/63 - 1s - loss: 2.4272e-04 - 744ms/epoch - 12ms/step\n",
            "Epoch 97/100\n",
            "63/63 - 1s - loss: 2.7350e-04 - 731ms/epoch - 12ms/step\n",
            "Epoch 98/100\n",
            "63/63 - 1s - loss: 2.4645e-04 - 727ms/epoch - 12ms/step\n",
            "Epoch 99/100\n",
            "63/63 - 1s - loss: 2.9661e-04 - 740ms/epoch - 12ms/step\n",
            "Epoch 100/100\n",
            "63/63 - 1s - loss: 2.4631e-04 - 754ms/epoch - 12ms/step\n",
            "63/63 [==============================] - 1s 5ms/step\n",
            "16/16 [==============================] - 0s 8ms/step\n",
            "Train MAE: 11.147809296112516\n",
            "Test MAE: 9.001719978131339\n",
            "Train RMSE: 15.846466963026373\n",
            "Test RMSE: 11.848806951511932\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Step 1: Load Time Series Data\n",
        "data = pd.read_csv(\"/content/sample_data/goldstock.csv\")\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_size = int(len(scaled_data) * 0.8)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train_data, test_data = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]\n",
        "\n",
        "# Function to create sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)-seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 10\n",
        "X_train, y_train = create_sequences(train_data, seq_length)\n",
        "X_test, y_test = create_sequences(test_data, seq_length)\n",
        "\n",
        "# Step 3: Build LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Step 4: Compile Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 5: Train Model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=2)\n",
        "\n",
        "# Step 6: Evaluate Model\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "y_train = scaler.inverse_transform(y_train.reshape(-1, 1))  # Reshape y_train to 2D array\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))    # Reshape y_test to 2D array\n",
        "\n",
        "# Calculate MAE and RMSE\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "train_mae = mean_absolute_error(y_train, train_predict)\n",
        "test_mae = mean_absolute_error(y_test, test_predict)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, train_predict))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_predict))\n",
        "\n",
        "print('Train MAE:', train_mae)\n",
        "print('Test MAE:', test_mae)\n",
        "print('Train RMSE:', train_rmse)\n",
        "print('Test RMSE:', test_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 1: Load MNIST Dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Step 3: Build CNN Model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Step 4: Compile Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train Model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n",
        "\n",
        "# Step 6: Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl5m2xgPLMF1",
        "outputId": "554d2b42-4b52-4d96-eea0-2569cb776621"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 28s 58ms/step - loss: 0.2333 - accuracy: 0.9336 - val_loss: 0.0904 - val_accuracy: 0.9755 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.0749 - accuracy: 0.9785 - val_loss: 0.0602 - val_accuracy: 0.9817 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.0505 - accuracy: 0.9851 - val_loss: 0.0548 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 26s 56ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.0432 - val_accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 27s 58ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.0462 - val_accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 31s 66ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0419 - val_accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0400 - val_accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0478 - val_accuracy: 0.9848 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0419 - val_accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 30s 64ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0457 - val_accuracy: 0.9863 - lr: 0.0010\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0457 - accuracy: 0.9863\n",
            "Test Accuracy: 0.986299991607666\n"
          ]
        }
      ]
    }
  ]
}